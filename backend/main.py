# ================================================================================================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ì„¹ì…˜
# ================================================================================================

# FastAPI: í˜„ëŒ€ì ì¸ ì›¹ API í”„ë ˆì„ì›Œí¬ (Django RESTë‚˜ Flaskë³´ë‹¤ ë¹ ë¦„)
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware  # ë¸Œë¼ìš°ì €ì—ì„œ API í˜¸ì¶œ í—ˆìš©

# Pydantic: ë°ì´í„° ê²€ì¦ ë° íƒ€ì… ì²´í¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pydantic import BaseModel, SecretStr  # API ìš”ì²­/ì‘ë‹µ ë°ì´í„° ëª¨ë¸ ì •ì˜ìš©

# ê¸°ë³¸ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import os  # íŒŒì¼ ì‹œìŠ¤í…œ ë° í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼
from typing import Optional, List, Dict  # íƒ€ì… íŒíŠ¸ìš© (ì½”ë“œ ê°€ë…ì„± í–¥ìƒ)

# LangChain: AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬
from langchain_community.vectorstores import Chroma  # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (ë¬¸ì„œ ê²€ìƒ‰ìš©)
from langchain_anthropic import ChatAnthropic  # Claude AI ëª¨ë¸ ì—°ë™
from langchain.prompts import ChatPromptTemplate  # AIì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
from langchain.schema.runnable import RunnablePassthrough  # ë°ì´í„° ì „ë‹¬ìš© íŒŒì´í”„ë¼ì¸
from langchain.schema import Document  # ë¬¸ì„œ ê°ì²´ (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°)
from langchain.text_splitter import MarkdownTextSplitter  # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
from langchain.embeddings.base import Embeddings  # ì„ë² ë”© ì¸í„°í˜ì´ìŠ¤ (í…ìŠ¤íŠ¸â†’ë²¡í„° ë³€í™˜)

# í™˜ê²½ì„¤ì • íŒŒì¼ ë¡œë“œìš©
from dotenv import load_dotenv  # .env íŒŒì¼ì—ì„œ API í‚¤ ë“± ë¯¼ê°ì •ë³´ ì½ê¸°

# ë³´ì•ˆ ë° ë„¤íŠ¸ì›Œí¬ ê´€ë ¨
import ssl  # HTTPS ë³´ì•ˆ ì—°ê²° ì„¤ì •
import urllib3  # HTTP í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import requests  # HTTP ìš”ì²­ ì²˜ë¦¬
from requests.adapters import HTTPAdapter  # HTTP ì—°ê²° ì–´ëŒ‘í„°
from urllib3.util.retry import Retry  # ìš”ì²­ ì‹¤íŒ¨ì‹œ ì¬ì‹œë„ ë¡œì§
from urllib3.poolmanager import PoolManager  # ì—°ê²° í’€ ê´€ë¦¬

# ì‹œìŠ¤í…œ ë° ìœ í‹¸ë¦¬í‹°
import gc  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ë©”ëª¨ë¦¬ ì •ë¦¬)
import re  # ì •ê·œí‘œí˜„ì‹
import uuid  # ê³ ìœ  ID ìƒì„±
from datetime import datetime, timedelta  # ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬
import asyncio  # ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°
from asyncio import Semaphore  # ë™ì‹œ ì‹¤í–‰ ì œí•œ (GPU ìì› ê´€ë¦¬ìš©)
import threading  # ë©€í‹°ìŠ¤ë ˆë”©
import time  # ì‹œê°„ ì¸¡ì •
import numpy as np  # ìˆ˜ì¹˜ ê³„ì‚° (ì„ë² ë”© ë²¡í„° ì²˜ë¦¬ìš©)
import atexit  # í”„ë¡œê·¸ë¨ ì¢…ë£Œì‹œ ì •ë¦¬ ì‘ì—…
import signal  # ì‹œìŠ¤í…œ ì‹ í˜¸ ì²˜ë¦¬

# ================================================================================================
# ì„ íƒì  AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬ Import (try-exceptë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
# ================================================================================================

# ONNX Runtime: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ ì‹¤í–‰í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ (íŠ¹íˆ GPU ê°€ì†ì— ìœ ìš©)
try:
    import onnxruntime as ort  # Microsoftì˜ AI ëª¨ë¸ ìµœì í™” ëŸ°íƒ€ì„
    ONNX_AVAILABLE = True  # ONNX ì‚¬ìš© ê°€ëŠ¥ í”Œë˜ê·¸
except ImportError:
    print("âš ï¸ ONNX Runtimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    ONNX_AVAILABLE = False

# Transformers: Hugging Faceì˜ ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from transformers.models.auto.tokenization_auto import AutoTokenizer  # í…ìŠ¤íŠ¸â†’í† í° ë³€í™˜ê¸°
    TRANSFORMERS_AVAILABLE = True  # Transformers ì‚¬ìš© ê°€ëŠ¥ í”Œë˜ê·¸
except ImportError:
    print("âš ï¸ Transformers íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    TRANSFORMERS_AVAILABLE = False

# Optimum: Hugging Face ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from optimum.onnxruntime import ORTModelForFeatureExtraction  # ì„ë² ë”© ëª¨ë¸ì˜ ONNX ë²„ì „
    OPTIMUM_AVAILABLE = True  # Optimum ì‚¬ìš© ê°€ëŠ¥ í”Œë˜ê·¸
except ImportError:
    print("âš ï¸ Optimum íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    OPTIMUM_AVAILABLE = False

# pynvml: NVIDIA GPU ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì‚¬í•­)
try:
    import pynvml  # GPU ë©”ëª¨ë¦¬, ì´ë¦„ ë“± í•˜ë“œì›¨ì–´ ì •ë³´ ì¡°íšŒìš©
    PYNVML_AVAILABLE = True  # GPU ì •ë³´ ì¡°íšŒ ê°€ëŠ¥ í”Œë˜ê·¸
except ImportError:
    print("ğŸ“ pynvmlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GPU ì •ë³´ í‘œì‹œê°€ ì œí•œë©ë‹ˆë‹¤.")
    PYNVML_AVAILABLE = False

# PyTorch: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ (ë¡œì»¬ ëª¨ë¸ ì‹¤í–‰ìš©)
try:
    import torch  # ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ë° ì‹¤í–‰
    TORCH_AVAILABLE = True  # PyTorch ì‚¬ìš© ê°€ëŠ¥ í”Œë˜ê·¸
except ImportError:
    print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©ì´ ì œí•œë©ë‹ˆë‹¤.")
    TORCH_AVAILABLE = False

# ================================================================================================
# HTTP í´ë¼ì´ì–¸íŠ¸ ì „ì—­ íŒ¨ì¹˜ (SSL ê²€ì¦ ë¹„í™œì„±í™” - ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½ìš©)
# ================================================================================================

# httpx: ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Claude API í˜¸ì¶œìš©)
import httpx

# ì›ë³¸ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜ë“¤ì„ ë°±ì—…
_original_client_init = httpx.Client.__init__  # ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì›ë³¸
_original_async_client_init = httpx.AsyncClient.__init__  # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì›ë³¸

def _patched_client_init(self, *args, **kwargs):
    """
    httpx.Clientì˜ íŒ¨ì¹˜ëœ ì´ˆê¸°í™” í•¨ìˆ˜
    - SSL ê²€ì¦ì„ ë¹„í™œì„±í™”í•˜ì—¬ ì¸ì¦ì„œ ë¬¸ì œë¥¼ íšŒí”¼
    - íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ì„¤ì •í•˜ì—¬ ëŠë¦° API ì‘ë‹µì— ëŒ€ë¹„
    """
    kwargs['verify'] = False  # SSL ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™”
    kwargs.setdefault('timeout', 60.0)  # ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ 60ì´ˆ
    return _original_client_init(self, *args, **kwargs)

def _patched_async_client_init(self, *args, **kwargs):
    """
    httpx.AsyncClientì˜ íŒ¨ì¹˜ëœ ì´ˆê¸°í™” í•¨ìˆ˜
    - ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ì—ë„ ë™ì¼í•œ SSL/íƒ€ì„ì•„ì›ƒ ì„¤ì • ì ìš©
    """
    kwargs['verify'] = False  # SSL ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™”
    kwargs.setdefault('timeout', 60.0)  # ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ 60ì´ˆ
    return _original_async_client_init(self, *args, **kwargs)

# httpx ëª¨ë“ˆì˜ ê¸°ë³¸ ë™ì‘ì„ íŒ¨ì¹˜ëœ ë²„ì „ìœ¼ë¡œ êµì²´
httpx.Client.__init__ = _patched_client_init
httpx.AsyncClient.__init__ = _patched_async_client_init

# SSL ì „ì—­ ì„¤ì •: ëª¨ë“  HTTPS ì—°ê²°ì—ì„œ ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™”
ssl._create_default_https_context = ssl._create_unverified_context

# urllib3 ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™” (SSL ê²€ì¦ ë¹„í™œì„±í™” ê²½ê³  ìˆ¨ê¹€)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class CustomHTTPAdapter(HTTPAdapter):
    """
    ì‚¬ìš©ì ì •ì˜ HTTP ì–´ëŒ‘í„° í´ë˜ìŠ¤
    - requests ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ SSL ê²€ì¦ì„ ë¹„í™œì„±í™”
    - ì—°ê²° í’€ ê´€ë¦¬ë¥¼ í†µí•´ ì„±ëŠ¥ ìµœì í™”
    """
    def init_poolmanager(self, connections, maxsize, block=False):
        """
        HTTP ì—°ê²° í’€ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        - SSL ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³  ê²€ì¦ì„ ë¹„í™œì„±í™”
        - ì—¬ëŸ¬ ì—°ê²°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬
        """
        ctx = ssl.create_default_context()  # ê¸°ë³¸ SSL ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        ctx.check_hostname = False  # í˜¸ìŠ¤íŠ¸ëª… ê²€ì¦ ë¹„í™œì„±í™”
        ctx.verify_mode = ssl.CERT_NONE  # ì¸ì¦ì„œ ê²€ì¦ ì™„ì „ ë¹„í™œì„±í™”
        self.poolmanager = PoolManager(
            num_pools=connections,  # ë™ì‹œ ì—°ê²° í’€ ê°œìˆ˜
            maxsize=maxsize,  # ê° í’€ì˜ ìµœëŒ€ ì—°ê²° ìˆ˜
            block=block,  # ì—°ê²° í’€ì´ ê½‰ ì°¼ì„ ë•Œ ëŒ€ê¸° ì—¬ë¶€
            ssl_version=ssl.PROTOCOL_TLS,  # TLS í”„ë¡œí† ì½œ ì‚¬ìš©
            ssl_context=ctx  # ìœ„ì—ì„œ ì„¤ì •í•œ SSL ì»¨í…ìŠ¤íŠ¸ ì ìš©
        )

# requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì „ì—­ ì„¤ì •
session = requests.Session()  # ì „ì—­ ì„¸ì…˜ ê°ì²´ ìƒì„±
adapter = CustomHTTPAdapter()  # ì»¤ìŠ¤í…€ ì–´ëŒ‘í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
session.mount("https://", adapter)  # HTTPS ìš”ì²­ì— ì»¤ìŠ¤í…€ ì–´ëŒ‘í„° ì ìš©
session.mount("http://", adapter)   # HTTP ìš”ì²­ì— ì»¤ìŠ¤í…€ ì–´ëŒ‘í„° ì ìš©
requests.Session = lambda: session  # ìƒˆë¡œìš´ Session ìƒì„±ì‹œ ìœ„ì˜ ì„¤ì •ëœ ì„¸ì…˜ ë°˜í™˜

# ================================================================================================
# SSL ì¸ì¦ì„œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •
# ================================================================================================

# SSL ì¸ì¦ì„œ íŒŒì¼ ê²½ë¡œ ì„¤ì • (íŠ¹ì • í™˜ê²½ì—ì„œ í•„ìš”í•œ ê²½ìš°)
cert_path = "C:\\cert\\sdj_ssl.crt"  # íšŒì‚¬/ê¸°ê´€ ì „ìš© SSL ì¸ì¦ì„œ ê²½ë¡œ
if os.path.exists(cert_path):
    # ì¸ì¦ì„œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    os.environ['CURL_CA_BUNDLE'] = cert_path      # cURL ë¼ì´ë¸ŒëŸ¬ë¦¬ìš© ì¸ì¦ì„œ
    os.environ['REQUESTS_CA_BUNDLE'] = cert_path  # requests ë¼ì´ë¸ŒëŸ¬ë¦¬ìš© ì¸ì¦ì„œ
    os.environ['SSL_CERT_FILE'] = cert_path       # ì¼ë°˜ SSL ì¸ì¦ì„œ íŒŒì¼
    os.environ['SSL_CERT_DIR'] = os.path.dirname(cert_path)  # ì¸ì¦ì„œ ë””ë ‰í† ë¦¬
else:
    # ì¸ì¦ì„œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •
    print(f"Warning: Certificate file not found at {cert_path}")
    os.environ['CURL_CA_BUNDLE'] = ''
    os.environ['REQUESTS_CA_BUNDLE'] = ''
    os.environ['SSL_CERT_FILE'] = ''
    os.environ['SSL_CERT_DIR'] = ''

# Python HTTPS ê²€ì¦ ì™„ì „ ë¹„í™œì„±í™” (ê°œë°œ í™˜ê²½ìš©)
os.environ['PYTHONHTTPSVERIFY'] = '0'

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (API í‚¤, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë“±)
load_dotenv()  # ANTHROPIC_API_KEY ë“±ì˜ ë¯¼ê°í•œ ì •ë³´ë¥¼ .env íŒŒì¼ì—ì„œ ì½ì–´ì˜´

# ================================================================================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ìƒìˆ˜ë“¤
# ================================================================================================

# AI ëª¨ë¸ ê´€ë ¨ ê²½ë¡œ ì„¤ì •
LOCAL_MODEL_PATH = os.path.abspath("./model_files")  # ë¡œì»¬ AI ëª¨ë¸ì´ ì €ì¥ëœ ì ˆëŒ€ ê²½ë¡œ

# ë¬¸ì„œ ì²˜ë¦¬ ê´€ë ¨ ì„¤ì •
CHUNK_SIZE = 500      # ë¬¸ì„œë¥¼ ë‚˜ëˆŒ ë•Œ í•œ ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜ (500ì ë‹¨ìœ„ë¡œ ë¶„í• )
CHUNK_OVERLAP = 50    # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (ì—°ê²°ì„± ìœ ì§€ë¥¼ ìœ„í•´ 50ìì”© ê²¹ì¹¨)
SEARCH_K = 3          # ë²¡í„° ê²€ìƒ‰ ì‹œ ë°˜í™˜í•  ìœ ì‚¬ ë¬¸ì„œì˜ ê°œìˆ˜ (ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ 3ê°œ)

# ë°ì´í„°ë² ì´ìŠ¤ ë° ìºì‹œ ë””ë ‰í† ë¦¬
CHROMA_DB_DIR = "./chroma_db"      # ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ
MODEL_CACHE_DIR = "./model_cache"  # AI ëª¨ë¸ ìºì‹œ ì €ì¥ ê²½ë¡œ  
ONNX_MODEL_DIR = "./onnx_models"   # ONNX ë³€í™˜ëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ

# ì„¸ì…˜ ê´€ë¦¬ ì„¤ì •
SESSION_TIMEOUT = timedelta(hours=1)  # ì‚¬ìš©ì ì„¸ì…˜ ë§Œë£Œ ì‹œê°„ (1ì‹œê°„)

# GPU ê°€ì† ê´€ë ¨ ì„¤ì •
FORCE_ONNX_MODE = os.getenv("FORCE_ONNX_MODE", "true").lower() == "true"  # ONNX ê°•ì œ ì‚¬ìš© í”Œë˜ê·¸
EMBEDDING_MODEL = LOCAL_MODEL_PATH  # ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ (ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©)

# ë™ì‹œ ì²˜ë¦¬ ì œí•œ ì„¤ì • (GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ìš©)
MAX_CONCURRENT_GPU_REQUESTS = 5  # ë™ì‹œì— GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ìš”ì²­ ìˆ˜
BATCH_SIZE = 16                  # í•œ ë²ˆì— ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸°
gpu_semaphore = Semaphore(MAX_CONCURRENT_GPU_REQUESTS)  # GPU ì‚¬ìš©ëŸ‰ ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´

# ================================================================================================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
# ================================================================================================

# FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì›¹ API ì„œë²„)
app = FastAPI()

# CORS (Cross-Origin Resource Sharing) ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
# ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ APIë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],        # ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì ‘ê·¼ í—ˆìš© (ê°œë°œìš©)
    allow_credentials=True,     # ì¿ í‚¤ ë° ì¸ì¦ ì •ë³´ í—ˆìš©
    allow_methods=["*"],        # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš© (GET, POST, PUT, DELETE ë“±)
    allow_headers=["*"],        # ëª¨ë“  HTTP í—¤ë” í—ˆìš©
)

# ================================================================================================
# ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic Models)
# ================================================================================================

class LoadDocumentRequest(BaseModel):
    """
    ë¬¸ì„œ ë¡œë“œ ìš”ì²­ ë°ì´í„° ëª¨ë¸
    - area: ê²€í† í•  ì˜ì—­ (ììœ¨/ìì¹˜í™œë™, ì§„ë¡œí™œë™ ë“±)
    - academic_level: í•™ì—… ìˆ˜ì¤€ (ê³ ë“±í•™êµ ë“±)
    """
    area: str            # íŠ¹ê¸°ì‚¬í•­ ì˜ì—­ (ì˜ˆ: "ììœ¨/ìì¹˜í™œë™ íŠ¹ê¸°ì‚¬í•­")
    academic_level: str  # í•™ì—… ìˆ˜ì¤€ (ì˜ˆ: "ê³ ë“±í•™êµ")

class ReviewRequest(BaseModel):
    """
    ë¬¸ì¥ ê²€í†  ìš”ì²­ ë°ì´í„° ëª¨ë¸
    - statement: ê²€í† í•  ë¬¸ì¥ ë‚´ìš©
    - session_id: ì„¸ì…˜ ì‹ë³„ì (ë¬¸ì„œê°€ ë¡œë“œëœ ì„¸ì…˜)
    """
    statement: str   # ê²€í†  ë°›ì„ ìƒê¸°ë¶€ ë¬¸ì¥
    session_id: str  # ì„¸ì…˜ ê³ ìœ  ID

class ReviewResponse(BaseModel):
    """
    ë¬¸ì¥ ê²€í†  ì‘ë‹µ ë°ì´í„° ëª¨ë¸
    - evaluation: ì í•©ì„± í‰ê°€ ê²°ê³¼
    - feedback: ê²€í†  ì˜ê²¬ ë° í”¼ë“œë°±
    - suggestion: ê°œì„  ì œì•ˆ ë¬¸ì¥
    - suggestion_length: ê°œì„  ì œì•ˆ ë¬¸ì¥ì˜ ê¸¸ì´
    """
    evaluation: str         # ë¬¸ì¥ ì í•©ì„± í‰ê°€
    feedback: str          # ìƒì„¸ í”¼ë“œë°±
    suggestion: str        # ê°œì„ ëœ ë¬¸ì¥ ì œì•ˆ
    suggestion_length: int # ì œì•ˆ ë¬¸ì¥ ê¸€ì ìˆ˜

class SessionInfo(BaseModel):
    """
    ì„¸ì…˜ ì •ë³´ ë°ì´í„° ëª¨ë¸
    - session_id: ì„¸ì…˜ ê³ ìœ  ì‹ë³„ì
    - created_at: ì„¸ì…˜ ìƒì„± ì‹œê°„
    - area: ê²€í†  ì˜ì—­
    - academic_level: í•™ì—… ìˆ˜ì¤€
    """
    session_id: str        # ì„¸ì…˜ ê³ ìœ  ID
    created_at: datetime   # ì„¸ì…˜ ìƒì„± ì‹œê°„
    area: str             # íŠ¹ê¸°ì‚¬í•­ ì˜ì—­
    academic_level: str   # í•™ì—… ìˆ˜ì¤€

# ================================================================================================
# ì „ì—­ ë³€ìˆ˜ ì„ ì–¸
# ================================================================================================

# AI ëª¨ë¸ ê´€ë ¨ ì „ì—­ ë³€ìˆ˜
tokenizer = None     # í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í† í¬ë‚˜ì´ì € ê°ì²´
ort_session = None   # ONNX Runtime ì„¸ì…˜ ê°ì²´ (GPU ê°€ì† ëª¨ë¸ ì¶”ë¡ ìš©)

# ì„¸ì…˜ ê´€ë¦¬ìš© ë”•ì…”ë„ˆë¦¬ (ë©”ëª¨ë¦¬ ìƒì—ì„œ ì‚¬ìš©ì ì„¸ì…˜ ì •ë³´ ì €ì¥)
sessions: Dict[str, dict] = {}  # í‚¤: session_id, ê°’: ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬

# ================================================================================================
# GPU ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ================================================================================================

def check_cuda_availability():
    """
    CUDA GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  GPU ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        tuple: (cuda_available, gpu_name, total_memory)
        - cuda_available (bool): CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        - gpu_name (str): GPU ì´ë¦„ (ì‚¬ìš© ë¶ˆê°€ì‹œ None)
        - total_memory (float): GPU ë©”ëª¨ë¦¬ í¬ê¸° (GB ë‹¨ìœ„, ì•Œ ìˆ˜ ì—†ìœ¼ë©´ "ì•Œ ìˆ˜ ì—†ìŒ")
    """
    # ONNX Runtimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° CUDA ì‚¬ìš© ë¶ˆê°€
    if not ONNX_AVAILABLE:
        return False, None, None
        
    try:
        # ONNX Runtimeì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í–‰ í”„ë¡œë°”ì´ë” ëª©ë¡ ì¡°íšŒ
        providers = ort.get_available_providers()
        cuda_available = 'CUDAExecutionProvider' in providers  # CUDA í”„ë¡œë°”ì´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        
        if cuda_available:
            # CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPU ì •ë³´ ìˆ˜ì§‘ ì‹œë„
            if PYNVML_AVAILABLE:
                try:
                    pynvml.nvmlInit()  # NVIDIA Management Library ì´ˆê¸°í™”
                    handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # ì²« ë²ˆì§¸ GPU í•¸ë“¤ íšë“
                    gpu_name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')  # GPU ì´ë¦„ ì¡°íšŒ
                    memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)  # ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ
                    total_memory = int(memory_info.total) / (1024**3)  # ë°”ì´íŠ¸ë¥¼ GBë¡œ ë³€í™˜
                    return True, gpu_name, total_memory
                except Exception as e:
                    print(f"pynvml ì˜¤ë¥˜: {str(e)}")
                    return True, "NVIDIA GPU", "ì•Œ ìˆ˜ ì—†ìŒ"  # GPUëŠ” ìˆì§€ë§Œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨
            else:
                # pynvmlì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
                return True, "NVIDIA GPU", "ì•Œ ìˆ˜ ì—†ìŒ"
        else:
            # CUDA í”„ë¡œë°”ì´ë”ê°€ ì—†ëŠ” ê²½ìš°
            return False, None, None
    except Exception as e:
        print(f"CUDA í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False, None, None

def setup_onnx_providers():
    """
    ONNX Runtime ì‹¤í–‰ í”„ë¡œë°”ì´ë”ë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
    GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDA í”„ë¡œë°”ì´ë”ë¥¼, ì•„ë‹ˆë©´ CPU í”„ë¡œë°”ì´ë”ë¥¼ ì„¤ì •
    
    Returns:
        list: ONNX Runtime í”„ë¡œë°”ì´ë” ì„¤ì • ë¦¬ìŠ¤íŠ¸
    """
    # ONNX Runtimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ì˜ˆì™¸ ë°œìƒ
    if not ONNX_AVAILABLE:
        raise Exception("ONNX Runtimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    cuda_available, gpu_name, gpu_memory = check_cuda_availability()
    
    if cuda_available:
        # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì˜ ë¡œê·¸ ì¶œë ¥
        print(f"ğŸš€ CUDA GPU ì‚¬ìš©: {gpu_name}")
        if gpu_memory != "ì•Œ ìˆ˜ ì—†ìŒ":
            print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
        print(f"ğŸ‘¥ ìµœëŒ€ ë™ì‹œ ì‚¬ìš©ì: {MAX_CONCURRENT_GPU_REQUESTS}")
        print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°: {BATCH_SIZE}")
        
        # CUDA í”„ë¡œë°”ì´ë” ì„¤ì • (GPU ê°€ì† í™œì„±í™”)
        providers = [
            ('CUDAExecutionProvider', {
                'device_id': 0,  # ì‚¬ìš©í•  GPU ì¥ì¹˜ ID (ì²« ë²ˆì§¸ GPU)
                'arena_extend_strategy': 'kNextPowerOfTwo',  # ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ
                'gpu_mem_limit': int(2 * 1024 * 1024 * 1024),  # GPU ë©”ëª¨ë¦¬ ì œí•œ (2GB)
                'cudnn_conv_algo_search': 'EXHAUSTIVE',  # ìµœì ì˜ CNN ì•Œê³ ë¦¬ì¦˜ íƒìƒ‰
                'do_copy_in_default_stream': True,  # ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ì—ì„œ ë©”ëª¨ë¦¬ ë³µì‚¬
            }),
            'CPUExecutionProvider'  # CUDA ì‹¤íŒ¨ì‹œ CPUë¡œ í´ë°±
        ]
    else:
        # GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° CPU ëª¨ë“œë¡œ ì‹¤í–‰
        print("ğŸ–¥ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        providers = ['CPUExecutionProvider']  # CPU í”„ë¡œë°”ì´ë”ë§Œ ì‚¬ìš©
    
    return providers

# ================================================================================================
# AI ëª¨ë¸ ë¡œë“œ ë° ONNX ë³€í™˜ í•¨ìˆ˜
# ================================================================================================

def download_and_cache_model():
    """
    ë¡œì»¬ AI ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  GPU ê°€ì†ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
    
    ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    1. ë¡œì»¬ì— ì €ì¥ëœ Transformers ëª¨ë¸ í™•ì¸
    2. í•„ìš”í•œ ê²½ìš° ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (GPU ìµœì í™”)
    3. í† í¬ë‚˜ì´ì €ì™€ ONNX ì„¸ì…˜ ì´ˆê¸°í™”
    4. ì „ì—­ ë³€ìˆ˜ì— ëª¨ë¸ ê°ì²´ë“¤ ì €ì¥
    
    ì£¼ì˜: SentenceTransformerë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³  Transformers + ONNX ì¡°í•© ì‚¬ìš©
    """
    global tokenizer, ort_session  # ì „ì—­ ë³€ìˆ˜ ìˆ˜ì •ì„ ìœ„í•œ ì„ ì–¸
    
    # 1ë‹¨ê³„: ë¡œì»¬ ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(EMBEDDING_MODEL):
        raise HTTPException(status_code=500, detail=f"ë¡œì»¬ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {EMBEDDING_MODEL}")
    
    try:
        print("ğŸ”„ ë¡œì»¬ ëª¨ë¸ ì§ì ‘ ONNX ë³€í™˜ ì¤‘...")
        print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {EMBEDDING_MODEL}")
        
        # 2ë‹¨ê³„: í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
        if not ONNX_AVAILABLE or not OPTIMUM_AVAILABLE:
            raise Exception("ONNX Runtime ë˜ëŠ” Optimum íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # 3ë‹¨ê³„: í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_path in [MODEL_CACHE_DIR, ONNX_MODEL_DIR]:
            if not os.path.exists(dir_path):
                os.makedirs(dir_path)  # ìºì‹œ ë° ONNX ëª¨ë¸ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ìƒì„±
        
        # 4ë‹¨ê³„: í† í¬ë‚˜ì´ì € ë¡œë“œ (í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬)
        tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL, local_files_only=True)
        
        # 5ë‹¨ê³„: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        onnx_model_path = os.path.join(ONNX_MODEL_DIR, "model.onnx")
        
        # 6ë‹¨ê³„: ONNX ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ë³€í™˜, ìˆìœ¼ë©´ ê¸°ì¡´ íŒŒì¼ ì‚¬ìš©
        if not os.path.exists(onnx_model_path):
            print("ğŸ“¦ Transformers ëª¨ë¸ì„ ì§ì ‘ ONNXë¡œ ë³€í™˜ ì¤‘...")
            
            # *** í•µì‹¬: SentenceTransformer ëŒ€ì‹  ì§ì ‘ ë³€í™˜ ë°©ì‹ ***
            from transformers.models.auto.modeling_auto import AutoModel
            
            # 6-1. PyTorch í˜•íƒœì˜ ì›ë³¸ ëª¨ë¸ ë¡œë“œ
            pytorch_model = AutoModel.from_pretrained(EMBEDDING_MODEL, local_files_only=True)
            
            # 6-2. ONNX ë³€í™˜ì„ ìœ„í•œ ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            temp_model_dir = os.path.join(MODEL_CACHE_DIR, "temp_for_onnx")
            os.makedirs(temp_model_dir, exist_ok=True)
            
            # 6-3. ì„ì‹œ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
            pytorch_model.save_pretrained(temp_model_dir)  # ëª¨ë¸ ì €ì¥
            tokenizer.save_pretrained(temp_model_dir)      # í† í¬ë‚˜ì´ì € ì €ì¥
            
            # 6-4. ONNX ë³€í™˜ ì‹¤í–‰ (GPU ìµœì í™”ëœ í˜•íƒœë¡œ ë³€í™˜)
            model = ORTModelForFeatureExtraction.from_pretrained(
                temp_model_dir,      # ë³€í™˜í•  ëª¨ë¸ ê²½ë¡œ
                export=True,         # ONNXë¡œ ë³€í™˜ í™œì„±í™”
                local_files_only=True # ë¡œì»¬ íŒŒì¼ë§Œ ì‚¬ìš©
            )
            model.save_pretrained(ONNX_MODEL_DIR)  # ë³€í™˜ëœ ONNX ëª¨ë¸ ì €ì¥
            
            # 6-5. ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ (ê³µê°„ ì ˆì•½)
            import shutil
            shutil.rmtree(temp_model_dir)
            
        else:
            # ì´ë¯¸ ONNX ë³€í™˜ëœ ëª¨ë¸ì´ ìˆëŠ” ê²½ìš° ë¡œë“œ
            print("ğŸ“ ê¸°ì¡´ ONNX ëª¨ë¸ ë¡œë“œ ì¤‘...")
            model = ORTModelForFeatureExtraction.from_pretrained(ONNX_MODEL_DIR)
        
        # 7ë‹¨ê³„: ONNX Runtime ì„¸ì…˜ ìƒì„± (ì‹¤ì œ ì¶”ë¡  ì—”ì§„)
        providers = setup_onnx_providers()  # GPU/CPU í”„ë¡œë°”ì´ë” ì„¤ì •
        
        # 7-1. ONNX íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
        onnx_files = [f for f in os.listdir(ONNX_MODEL_DIR) if f.endswith('.onnx')]
        if onnx_files:
            actual_onnx_path = os.path.join(ONNX_MODEL_DIR, onnx_files[0])  # ì²« ë²ˆì§¸ .onnx íŒŒì¼ ì‚¬ìš©
        else:
            actual_onnx_path = model.model_path  # ëª¨ë¸ ê°ì²´ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        
        # 7-2. ONNX Runtime ì„¸ì…˜ ì˜µì…˜ ì„¤ì •
        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL  # ëª¨ë“  ìµœì í™” í™œì„±í™”
        
        # 7-3. ONNX Runtime ì¶”ë¡  ì„¸ì…˜ ìƒì„±
        ort_session = ort.InferenceSession(
            actual_onnx_path,  # ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            sess_options,      # ì„¸ì…˜ ì˜µì…˜ (ìµœì í™” ì„¤ì •)
            providers=providers # ì‹¤í–‰ í”„ë¡œë°”ì´ë” (GPU/CPU)
        )
        
        # ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥
        print("âœ… ë¡œì»¬ ëª¨ë¸ ONNX+GPU ë³€í™˜ ì™„ë£Œ!")
        print(f"ğŸ”§ ì‚¬ìš© ì¤‘ì¸ í”„ë¡œë°”ì´ë”: {ort_session.get_providers()}")
        
        return tokenizer, ort_session  # í† í¬ë‚˜ì´ì €ì™€ ONNX ì„¸ì…˜ ë°˜í™˜
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒì‹œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ë° HTTP ì˜ˆì™¸ ë°œìƒ
        print(f"ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì§ì ‘ ONNX ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ================================================================================================
# ì„ë² ë”© ìƒì„± í•¨ìˆ˜ë“¤ (í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜)
# ================================================================================================

async def get_embeddings_batch_unified(texts, tokenizer, model_or_session):
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í†µí•© í•¨ìˆ˜
    PyTorch ëª¨ë¸ê³¼ ONNX Runtime ì„¸ì…˜ ëª¨ë‘ ì§€ì›
    
    Args:
        texts (list): ë³€í™˜í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        tokenizer: í† í¬ë‚˜ì´ì € ê°ì²´ (í…ìŠ¤íŠ¸â†’í† í° ë³€í™˜)
        model_or_session: PyTorch ëª¨ë¸ ë˜ëŠ” ONNX Runtime ì„¸ì…˜
        
    Returns:
        list: ê° í…ìŠ¤íŠ¸ì— ëŒ€ì‘í•˜ëŠ” ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
    """
    # GPU ì‚¬ìš©ëŸ‰ ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´ ì‚¬ìš© (ë™ì‹œ ì²˜ë¦¬ ì œí•œ)
    async with gpu_semaphore:
        try:
            all_embeddings = []  # ëª¨ë“  ì„ë² ë”© ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            
            # ëª¨ë¸ íƒ€ì… í™•ì¸ (ONNX Runtime ì„¸ì…˜ì¸ì§€ PyTorch ëª¨ë¸ì¸ì§€)
            is_onnx = hasattr(model_or_session, 'run')  # ONNX ì„¸ì…˜ì€ run ë©”ì„œë“œê°€ ìˆìŒ
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´)
            for i in range(0, len(texts), BATCH_SIZE):
                batch_texts = texts[i:i + BATCH_SIZE]  # í˜„ì¬ ë°°ì¹˜ì˜ í…ìŠ¤íŠ¸ë“¤
                
                if is_onnx:
                    # ONNX Runtimeì„ ì‚¬ìš©í•œ ì¶”ë¡  ë°©ì‹
                    
                    # 1. í† í¬ë‚˜ì´ì €ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜
                    inputs = tokenizer(
                        batch_texts,           # ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ë°°ì¹˜
                        padding=True,          # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©
                        truncation=True,       # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ì‹œ ìë¥´ê¸°
                        max_length=512,        # ìµœëŒ€ í† í° ê¸¸ì´ (BERT ê³„ì—´ í‘œì¤€)
                        return_tensors="np"    # NumPy ë°°ì—´ë¡œ ë°˜í™˜
                    )
                    
                    # 2. ONNX ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (int64 íƒ€ì… í•„ìˆ˜)
                    ort_inputs = {
                        'input_ids': inputs['input_ids'].astype(np.int64),         # í† í° ID ë°°ì—´
                        'attention_mask': inputs['attention_mask'].astype(np.int64) # íŒ¨ë”© ë§ˆìŠ¤í¬
                    }
                    
                    # 3. ONNX ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
                    outputs = model_or_session.run(None, ort_inputs)  # ìˆœì „íŒŒ ì‹¤í–‰
                    last_hidden_state = outputs[0]  # ë§ˆì§€ë§‰ ì€ë‹‰ì¸µ ì¶œë ¥ (ë¬¸ë§¥ ì„ë² ë”©)
                    
                    # 4. Mean Pooling ìˆ˜í–‰ (í† í° ì„ë² ë”©ë“¤ì˜ í‰ê·  ê³„ì‚°)
                    attention_mask = inputs['attention_mask']
                    mask_expanded = np.expand_dims(attention_mask, axis=-1)  # ì°¨ì› í™•ì¥
                    mask_expanded = np.broadcast_to(mask_expanded, last_hidden_state.shape)  # ë¸Œë¡œë“œìºìŠ¤íŒ…
                    
                    # íŒ¨ë”© í† í°ì€ ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚°
                    sum_embeddings = np.sum(last_hidden_state * mask_expanded, axis=1)  # ë§ˆìŠ¤í‚¹ í›„ í•©ê³„
                    sum_mask = np.sum(mask_expanded, axis=1)  # ìœ íš¨ í† í° ê°œìˆ˜
                    sum_mask = np.clip(sum_mask, a_min=1e-9, a_max=None)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                    
                    embeddings = sum_embeddings / sum_mask  # í‰ê·  ì„ë² ë”© ê³„ì‚°
                    
                    # 5. L2 ì •ê·œí™” (ë²¡í„° ê¸¸ì´ë¥¼ 1ë¡œ ë§Œë“¤ì–´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ìµœì í™”)
                    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)  # ë²¡í„° í¬ê¸° ê³„ì‚°
                    norms = np.clip(norms, a_min=1e-9, a_max=None)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                    embeddings = embeddings / norms  # ì •ê·œí™”ëœ ì„ë² ë”©
                    
                    batch_embeddings = embeddings.tolist()  # Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    
                else:
                    # PyTorchë¥¼ ì‚¬ìš©í•œ ì¶”ë¡  ë°©ì‹
                    import torch
                    
                    # 1. ëª¨ë¸ì´ ì‹¤í–‰ë˜ê³  ìˆëŠ” ë””ë°”ì´ìŠ¤ í™•ì¸ (CPU or GPU)
                    device = next(model_or_session.parameters()).device
                    
                    # 2. í† í¬ë‚˜ì´ì €ë¡œ í…ìŠ¤íŠ¸ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
                    inputs = tokenizer(
                        batch_texts,           # ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ë°°ì¹˜
                        padding=True,          # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©
                        truncation=True,       # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ì‹œ ìë¥´ê¸°
                        max_length=512,        # ìµœëŒ€ í† í° ê¸¸ì´
                        return_tensors="pt"    # PyTorch í…ì„œë¡œ ë°˜í™˜
                    )
                    
                    # 3. ì…ë ¥ í…ì„œë¥¼ ëª¨ë¸ê³¼ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ (GPU/CPU)
                    inputs = {k: v.to(device) for k, v in inputs.items()}
                    
                    # 4. ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì¶”ë¡  ëª¨ë“œ, ë©”ëª¨ë¦¬ ì ˆì•½)
                    with torch.no_grad():
                        outputs = model_or_session(**inputs)  # ëª¨ë¸ ìˆœì „íŒŒ
                        last_hidden_state = outputs.last_hidden_state  # ë§ˆì§€ë§‰ ì€ë‹‰ì¸µ ì¶œë ¥
                        
                        # 5. Mean Pooling ìˆ˜í–‰ (í† í° ì„ë² ë”©ë“¤ì˜ í‰ê·  ê³„ì‚°)
                        attention_mask = inputs['attention_mask']
                        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()
                        
                        # íŒ¨ë”© í† í° ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚°
                        sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)  # ë§ˆìŠ¤í‚¹ í›„ í•©ê³„
                        sum_mask = torch.sum(mask_expanded, 1)  # ìœ íš¨ í† í° ê°œìˆ˜
                        sum_mask = torch.clamp(sum_mask, min=1e-9)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                        
                        embeddings = sum_embeddings / sum_mask  # í‰ê·  ì„ë² ë”© ê³„ì‚°
                        
                        # 6. L2 ì •ê·œí™” (ë²¡í„° ê¸¸ì´ë¥¼ 1ë¡œ ë§Œë“¤ê¸°)
                        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
                        
                        # 7. CPUë¡œ ì´ë™ í›„ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        batch_embeddings = embeddings.cpu().tolist()
                
                # í˜„ì¬ ë°°ì¹˜ì˜ ì„ë² ë”©ì„ ì „ì²´ ê²°ê³¼ì— ì¶”ê°€
                all_embeddings.extend(batch_embeddings)
            
            return all_embeddings  # ëª¨ë“  í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„° ë°˜í™˜
            
        except Exception as e:
            # ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒì‹œ HTTP ì˜ˆì™¸ë¡œ ë³€í™˜
            raise HTTPException(status_code=500, detail=f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

async def get_embeddings_unified(text, tokenizer, model_or_session):
    """
    ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    ë‚´ë¶€ì ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
    
    Args:
        text (str): ë³€í™˜í•  ë‹¨ì¼ í…ìŠ¤íŠ¸
        tokenizer: í† í¬ë‚˜ì´ì € ê°ì²´
        model_or_session: PyTorch ëª¨ë¸ ë˜ëŠ” ONNX Runtime ì„¸ì…˜
        
    Returns:
        list: ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°
    """
    # ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ë°°ì¹˜ í•¨ìˆ˜ í˜¸ì¶œ
    results = await get_embeddings_batch_unified([text], tokenizer, model_or_session)
    return results[0]  # ì²« ë²ˆì§¸ (ìœ ì¼í•œ) ê²°ê³¼ ë°˜í™˜

class UnifiedEmbeddingFunction(Embeddings):
    """
    ChromaDB í˜¸í™˜ ì„ë² ë”© í•¨ìˆ˜ í´ë˜ìŠ¤
    PyTorchì™€ ONNX Runtimeì„ ëª¨ë‘ ì§€ì›í•˜ëŠ” í†µí•© ì„ë² ë”© ì¸í„°í˜ì´ìŠ¤
    
    LangChainì˜ Embeddings ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ChromaDBì—ì„œ ì‚¬ìš© ê°€ëŠ¥
    """
    def __init__(self, tokenizer, model_or_session):
        """
        ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™”
        
        Args:
            tokenizer: í† í¬ë‚˜ì´ì € ê°ì²´
            model_or_session: PyTorch ëª¨ë¸ ë˜ëŠ” ONNX Runtime ì„¸ì…˜
        """
        self.tokenizer = tokenizer           # í…ìŠ¤íŠ¸â†’í† í° ë³€í™˜ê¸°
        self.model_or_session = model_or_session  # AI ëª¨ë¸ ê°ì²´

    def embed_documents(self, texts):
        """
        ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì„œë“œ (ChromaDB í˜¸í™˜)
        ChromaDBê°€ ë¬¸ì„œë“¤ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•  ë•Œ í˜¸ì¶œ
        
        Args:
            texts (list): ë³€í™˜í•  ë¬¸ì„œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            list: ê° ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            return self._get_embeddings_batch_sync(texts)  # ë™ê¸° ë°©ì‹ ë°°ì¹˜ ì²˜ë¦¬
        except Exception as e:
            print(f"ë¬¸ì„œ ì„ë² ë”© ì˜¤ë¥˜: {str(e)}")
            raise

    def embed_query(self, text):
        """
        ë‹¨ì¼ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì„œë“œ (ChromaDB í˜¸í™˜)
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì— ì‚¬ìš©
        
        Args:
            text (str): ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸
            
        Returns:
            list: ì¿¼ë¦¬ì˜ ì„ë² ë”© ë²¡í„°
        """
        try:
            results = self._get_embeddings_batch_sync([text])  # ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬
            return results[0]  # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
        except Exception as e:
            print(f"ì¿¼ë¦¬ ì„ë² ë”© ì˜¤ë¥˜: {str(e)}")
            raise

    def _get_embeddings_batch_sync(self, texts):
        """
        ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”© ìƒì„±
        ChromaDBì—ì„œ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œ (ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ë¡œ ë˜í•‘)
        
        Args:
            texts (list): ë³€í™˜í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            list: ê° í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            all_embeddings = []  # ëª¨ë“  ì„ë² ë”© ê²°ê³¼ ì €ì¥ìš©
            
            # ëª¨ë¸ íƒ€ì… í™•ì¸ (ONNX Runtime ì„¸ì…˜ì¸ì§€ PyTorch ëª¨ë¸ì¸ì§€)
            is_onnx = hasattr(self.model_or_session, 'run')  # ONNX ì„¸ì…˜ì€ run ë©”ì„œë“œ ìˆìŒ
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            for i in range(0, len(texts), BATCH_SIZE):
                batch_texts = texts[i:i + BATCH_SIZE]  # í˜„ì¬ ë°°ì¹˜ í…ìŠ¤íŠ¸ë“¤
                
                if is_onnx:
                    # ONNX Runtimeì„ ì‚¬ìš©í•œ ë™ê¸° ë°©ì‹ ì¶”ë¡ 
                    
                    # 1. í† í¬ë‚˜ì´ì €ë¡œ í…ìŠ¤íŠ¸ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
                    inputs = self.tokenizer(
                        batch_texts,           # ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ë°°ì¹˜
                        padding=True,          # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©
                        truncation=True,       # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ì‹œ ìë¥´ê¸°
                        max_length=512,        # ìµœëŒ€ í† í° ê¸¸ì´
                        return_tensors="np"    # NumPy ë°°ì—´ë¡œ ë°˜í™˜
                    )
                    
                    # 2. ONNX ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    ort_inputs = {
                        'input_ids': inputs['input_ids'].astype(np.int64),         # í† í° ID
                        'attention_mask': inputs['attention_mask'].astype(np.int64) # íŒ¨ë”© ë§ˆìŠ¤í¬
                    }
                    
                    # 3. ONNX ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                    outputs = self.model_or_session.run(None, ort_inputs)
                    last_hidden_state = outputs[0]  # ë§ˆì§€ë§‰ ì€ë‹‰ì¸µ ì¶œë ¥
                    
                    # 4. Mean Pooling ìˆ˜í–‰
                    attention_mask = inputs['attention_mask']
                    mask_expanded = np.expand_dims(attention_mask, axis=-1)
                    mask_expanded = np.broadcast_to(mask_expanded, last_hidden_state.shape)
                    
                    # íŒ¨ë”© í† í° ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚°
                    sum_embeddings = np.sum(last_hidden_state * mask_expanded, axis=1)
                    sum_mask = np.sum(mask_expanded, axis=1)
                    sum_mask = np.clip(sum_mask, a_min=1e-9, a_max=None)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                    
                    embeddings = sum_embeddings / sum_mask  # í‰ê·  ì„ë² ë”©
                    
                    # 5. L2 ì •ê·œí™”
                    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
                    norms = np.clip(norms, a_min=1e-9, a_max=None)
                    embeddings = embeddings / norms  # ì •ê·œí™”ëœ ì„ë² ë”©
                    
                    batch_embeddings = embeddings.tolist()  # Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    
                else:
                    # PyTorchë¥¼ ì‚¬ìš©í•œ ë™ê¸° ë°©ì‹ ì¶”ë¡ 
                    import torch
                    
                    # 1. ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸
                    device = next(self.model_or_session.parameters()).device
                    
                    # 2. í† í¬ë‚˜ì´ì €ë¡œ PyTorch í…ì„œ ìƒì„±
                    inputs = self.tokenizer(
                        batch_texts,           # ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ë°°ì¹˜
                        padding=True,          # íŒ¨ë”© ì ìš©
                        truncation=True,       # ê¸¸ì´ ì œí•œ
                        max_length=512,        # ìµœëŒ€ í† í° ê¸¸ì´
                        return_tensors="pt"    # PyTorch í…ì„œë¡œ ë°˜í™˜
                    )
                    
                    # 3. ì…ë ¥ì„ ëª¨ë¸ê³¼ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                    inputs = {k: v.to(device) for k, v in inputs.items()}
                    
                    # 4. ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™”í•˜ì—¬ ì¶”ë¡  ìˆ˜í–‰
                    with torch.no_grad():
                        outputs = self.model_or_session(**inputs)  # ëª¨ë¸ ì¶”ë¡ 
                        last_hidden_state = outputs.last_hidden_state
                        
                        # 5. Mean Pooling ìˆ˜í–‰
                        attention_mask = inputs['attention_mask']
                        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()
                        
                        # íŒ¨ë”© í† í° ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚°
                        sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)
                        sum_mask = torch.sum(mask_expanded, 1)
                        sum_mask = torch.clamp(sum_mask, min=1e-9)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                        
                        embeddings = sum_embeddings / sum_mask  # í‰ê·  ì„ë² ë”©
                        
                        # 6. L2 ì •ê·œí™”
                        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
                        
                        # 7. CPUë¡œ ì´ë™ í›„ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
                        batch_embeddings = embeddings.cpu().tolist()
                
                # ë°°ì¹˜ ê²°ê³¼ë¥¼ ì „ì²´ ê²°ê³¼ì— ì¶”ê°€
                all_embeddings.extend(batch_embeddings)
            
            return all_embeddings  # ëª¨ë“  ì„ë² ë”© ë°˜í™˜
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒì‹œ ì˜ˆì™¸ ì „íŒŒ
            raise Exception(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ================================================================================================
# ì„¸ì…˜ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ================================================================================================

def cleanup_expired_sessions():
    """
    ë§Œë£Œëœ ì‚¬ìš©ì ì„¸ì…˜ë“¤ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
    ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ë° ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½ì„ ìœ„í•´ ì •ê¸°ì ìœ¼ë¡œ í˜¸ì¶œë¨
    
    ì²˜ë¦¬ ê³¼ì •:
    1. í˜„ì¬ ì‹œê°„ê³¼ ë¹„êµí•˜ì—¬ ë§Œë£Œëœ ì„¸ì…˜ ì‹ë³„
    2. ë©”ëª¨ë¦¬ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ ì •ë¦¬
    3. íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ
    4. ì„¸ì…˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì œê±°
    """
    current_time = datetime.now()  # í˜„ì¬ ì‹œê°„ íšë“
    
    # ë§Œë£Œëœ ì„¸ì…˜ ID ëª©ë¡ ìƒì„± (ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ì‚¬ìš©)
    expired_sessions = [
        session_id for session_id, session_data in sessions.items()
        if current_time - session_data['created_at'] > SESSION_TIMEOUT  # 1ì‹œê°„ ì´ˆê³¼ ì„¸ì…˜
    ]
    
    # ê° ë§Œë£Œëœ ì„¸ì…˜ì— ëŒ€í•´ ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
    for session_id in expired_sessions:
        try:
            # 1ë‹¨ê³„: ë©”ëª¨ë¦¬ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ ì •ë¦¬
            if session_id in sessions and 'vectorstore' in sessions[session_id]:
                vectorstore = sessions[session_id]['vectorstore']  # ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ íšë“
                # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì •ë¦¬
                if hasattr(vectorstore, '_client') and vectorstore._client:
                    try:
                        vectorstore._client.reset()  # í´ë¼ì´ì–¸íŠ¸ ë¦¬ì…‹
                    except:
                        pass  # ë¦¬ì…‹ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                del vectorstore  # ê°ì²´ ì‚­ì œë¡œ ë©”ëª¨ë¦¬ í•´ì œ
            
            # 2ë‹¨ê³„: ì„¸ì…˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì œê±°
            if session_id in sessions:
                del sessions[session_id]  # ë©”ëª¨ë¦¬ì—ì„œ ì„¸ì…˜ ë°ì´í„° ì œê±°
            
            # 3ë‹¨ê³„: íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)
            session_dir = os.path.join(CHROMA_DB_DIR, session_id)  # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            if os.path.exists(session_dir):
                import shutil  # ë””ë ‰í† ë¦¬ ì‚­ì œìš©
                import time    # ëŒ€ê¸° ì‹œê°„ìš©
                
                # Windows íŒŒì¼ ì‹œìŠ¤í…œì˜ íŒŒì¼ ì ê¸ˆ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¬ì‹œë„ ë¡œì§
                max_retries = 3  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
                for attempt in range(max_retries):
                    try:
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ë¡œ íŒŒì¼ í•¸ë“¤ í•´ì œ
                        import gc
                        gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
                        
                        # ì²« ë²ˆì§¸ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì ì‹œ ëŒ€ê¸° (íŒŒì¼ ì ê¸ˆ í•´ì œ ëŒ€ê¸°)
                        if attempt > 0:
                            time.sleep(0.5)  # 0.5ì´ˆ ëŒ€ê¸°
                        
                        shutil.rmtree(session_dir)  # ë””ë ‰í† ë¦¬ ë° í•˜ìœ„ íŒŒì¼ ëª¨ë‘ ì‚­ì œ
                        print(f"âœ… ë§Œë£Œëœ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ ì™„ë£Œ: {session_id}")
                        break  # ì„±ê³µì‹œ ì¬ì‹œë„ ë£¨í”„ ì¢…ë£Œ
                        
                    except PermissionError as e:
                        # íŒŒì¼ ê¶Œí•œ ì˜¤ë¥˜ (Windowsì—ì„œ í”íˆ ë°œìƒ)
                        if attempt == max_retries - 1:
                            print(f"âš ï¸ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨ (ê¶Œí•œ ë¬¸ì œ): {session_id} - {str(e)}")
                            # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ë©”ëª¨ë¦¬ëŠ” ì´ë¯¸ ì •ë¦¬í–ˆìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
                        else:
                            print(f"ğŸ”„ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries}): {session_id}")
                    except Exception as e:
                        print(f"âŒ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {session_id} - {str(e)}")
                        break  # ë‹¤ë¥¸ ì˜ˆì™¸ ë°œìƒì‹œ ì¬ì‹œë„ ì¤‘ë‹¨
                        
        except Exception as e:
            print(f"âŒ ì„¸ì…˜ ì •ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {session_id} - {str(e)}")
            # ê°œë³„ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì„¸ì…˜ë“¤ì€ ê³„ì† ì²˜ë¦¬ (continueë¡œ ë‹¤ìŒ ì„¸ì…˜ìœ¼ë¡œ)
            continue

# ================================================================================================
# REST API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ================================================================================================

@app.post("/api/load-documents")
async def load_documents(request: LoadDocumentRequest):
    """
    ë¬¸ì„œ ë¡œë“œ API ì—”ë“œí¬ì¸íŠ¸
    
    ê¸°ëŠ¥:
    1. ì„ íƒëœ ì˜ì—­(ììœ¨/ìì¹˜í™œë™ ë˜ëŠ” ì§„ë¡œí™œë™)ì˜ ê°€ì´ë“œë¼ì¸ ë¬¸ì„œë“¤ì„ ë¡œë“œ
    2. ë¬¸ì„œë“¤ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    3. ì‚¬ìš©ìë³„ ê³ ìœ  ì„¸ì…˜ ìƒì„± ë° ê´€ë¦¬
    
    Args:
        request (LoadDocumentRequest): ë¡œë“œí•  ì˜ì—­ê³¼ í•™ì—… ìˆ˜ì¤€ ì •ë³´
        
    Returns:
        dict: ì„¸ì…˜ IDì™€ ì„œë²„ ì •ë³´ê°€ í¬í•¨ëœ ì‘ë‹µ
    """
    try:
        # 1ë‹¨ê³„: ë§Œë£Œëœ ê¸°ì¡´ ì„¸ì…˜ë“¤ì„ ì •ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ í™•ë³´
        cleanup_expired_sessions()
        
        # 2ë‹¨ê³„: ì‚¬ìš©ìê°€ ì„ íƒí•œ ì˜ì—­ì„ ì‹¤ì œ ë””ë ‰í† ë¦¬ëª…ìœ¼ë¡œ ë§¤í•‘
        area_map = {
            "ììœ¨/ìì¹˜í™œë™ íŠ¹ê¸°ì‚¬í•­": "self_governance_guidelines",  # ììœ¨/ìì¹˜í™œë™ ê°€ì´ë“œë¼ì¸
            "ì§„ë¡œí™œë™ íŠ¹ê¸°ì‚¬í•­": "career_activity_guidelines"        # ì§„ë¡œí™œë™ ê°€ì´ë“œë¼ì¸
        }
        
        # 3ë‹¨ê³„: ìœ íš¨í•œ ì˜ì—­ì¸ì§€ ê²€ì¦
        if request.area not in area_map:
            raise HTTPException(status_code=400, detail=f"Invalid area selected: {request.area}")
        
        # 4ë‹¨ê³„: í•´ë‹¹ ì˜ì—­ì˜ ë¬¸ì„œ ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„±
        directory = f"data/{area_map[request.area]}"
        if not os.path.exists(directory):
            raise HTTPException(status_code=404, detail=f"Directory not found: {directory}")
        
        # 5ë‹¨ê³„: ë””ë ‰í† ë¦¬ì— ë¬¸ì„œ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
        if not os.listdir(directory):
            raise HTTPException(status_code=404, detail=f"Directory is empty: {directory}")
        
        # 6ë‹¨ê³„: ìƒˆë¡œìš´ ì‚¬ìš©ì ì„¸ì…˜ì„ ìœ„í•œ ê³ ìœ  ID ìƒì„±
        session_id = str(uuid.uuid4())  # UUID4ë¡œ ì¶©ëŒ ì—†ëŠ” ê³ ìœ  ID ìƒì„±
        session_db_dir = os.path.join(CHROMA_DB_DIR, session_id)  # ì„¸ì…˜ë³„ ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
        
        # 7ë‹¨ê³„: ë””ë ‰í† ë¦¬ì—ì„œ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ íŒŒì¼ë“¤ì„ ë¡œë“œ
        documents = []  # ë¡œë“œëœ ë¬¸ì„œë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        for file_path in os.listdir(directory):
            try:
                if file_path.endswith('.md'):  # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë§Œ ì²˜ë¦¬
                    with open(os.path.join(directory, file_path), 'r', encoding='utf-8') as f:
                        content = f.read()  # íŒŒì¼ ë‚´ìš© ì½ê¸°
                        # Document ê°ì²´ ìƒì„± (ë‚´ìš© + ë©”íƒ€ë°ì´í„°)
                        documents.append(Document(page_content=content, metadata={"source": file_path}))
            except Exception as e:
                print(f"Error reading file {file_path}: {str(e)}")  # íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ë¡œê·¸
        
        # 8ë‹¨ê³„: ë¡œë“œëœ ë¬¸ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
        if len(documents) == 0:
            raise HTTPException(status_code=404, detail=f"No markdown files found in {directory}")
        
        # 9ë‹¨ê³„: ë¬¸ì„œë“¤ì„ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
        text_splitter = MarkdownTextSplitter(
            chunk_size=CHUNK_SIZE,      # ì²­í¬ë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜ (500ì)
            chunk_overlap=CHUNK_OVERLAP # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (50ì, ë¬¸ë§¥ ì—°ê²°ì„± ìœ ì§€)
        )
        splits = text_splitter.split_documents(documents)  # ë¬¸ì„œ ë¶„í•  ì‹¤í–‰
        
        # 10ë‹¨ê³„: AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ
        if tokenizer is None or ort_session is None:
            try:
                download_and_cache_model()  # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ONNX ë³€í™˜
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error downloading model: {str(e)}")
        
        # 11ë‹¨ê³„: ì„ë² ë”© í•¨ìˆ˜ ìƒì„± (ChromaDB í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤)
        embedding_function = UnifiedEmbeddingFunction(tokenizer, ort_session)
        
        try:
            # 12ë‹¨ê³„: ì„¸ì…˜ë³„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(session_db_dir, exist_ok=True)
            
            # 13ë‹¨ê³„: ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ íƒ€ì… í™•ì¸ (ë¡œê·¸ ì¶œë ¥ìš©)
            is_local_model = (os.path.exists(EMBEDDING_MODEL) and 
                            os.path.isdir(EMBEDDING_MODEL) and
                            os.path.exists(os.path.join(EMBEDDING_MODEL, "config.json")))
            
            # 14ë‹¨ê³„: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ê°€ì† ë°©ì‹ ê²°ì •
            if FORCE_ONNX_MODE:
                acceleration_type = "ONNX Runtime (GPU)"  # ê°•ì œ ONNX ëª¨ë“œ
            elif hasattr(ort_session, 'run'):  # ONNX ì„¸ì…˜ í™•ì¸
                acceleration_type = "ONNX Runtime"
            else:  # PyTorch ëª¨ë¸
                acceleration_type = "PyTorch (ë¡œì»¬)"
            
            # 15ë‹¨ê³„: ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘ ë¡œê·¸
            print(f"ğŸ“Š {acceleration_type}ë¡œ ë¬¸ì„œ {len(splits)}ê°œ ì²˜ë¦¬ ì¤‘... (ì‚¬ìš©ì: {len(sessions)+1}ëª…)")
            start_time = time.time()  # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì‹œì‘
            
            # 16ë‹¨ê³„: ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (í•µì‹¬ ê³¼ì •)
            vectorstore = Chroma.from_documents(
                documents=splits,               # ë¶„í• ëœ ë¬¸ì„œ ì²­í¬ë“¤
                embedding=embedding_function,   # ì„ë² ë”© í•¨ìˆ˜ (í…ìŠ¤íŠ¸â†’ë²¡í„° ë³€í™˜)
                persist_directory=session_db_dir # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ
            )
            
            end_time = time.time()  # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì™„ë£Œ
            print(f"âš¡ {acceleration_type} ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {end_time - start_time:.1f}ì´ˆ")
            
            # 17ë‹¨ê³„: ì„¸ì…˜ ì •ë³´ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
            sessions[session_id] = {
                'vectorstore': vectorstore,     # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê°ì²´
                'created_at': datetime.now(),   # ì„¸ì…˜ ìƒì„± ì‹œê°„
                'area': request.area,           # ì„ íƒëœ ì˜ì—­
                'academic_level': request.academic_level  # í•™ì—… ìˆ˜ì¤€
            }
            
        except Exception as e:
            # ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒì‹œ HTTP ì˜ˆì™¸ë¡œ ë³€í™˜
            raise HTTPException(status_code=500, detail=f"Error creating vectorstore: {str(e)}")
        
        # 18ë‹¨ê³„: ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ë¹„ì§€ ì»¬ë ‰ì…˜)
        gc.collect()
        
        # 19ë‹¨ê³„: í˜„ì¬ í™œì„± ì„¸ì…˜ ìˆ˜ í™•ì¸
        active_sessions = len(sessions)
        
        # 20ë‹¨ê³„: ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {
            "status": "success",
            "message": f"Documents loaded successfully with {acceleration_type}",
            "session_id": session_id,  # í´ë¼ì´ì–¸íŠ¸ê°€ í›„ì† ìš”ì²­ì—ì„œ ì‚¬ìš©í•  ì„¸ì…˜ ID
            "server_info": {
                "active_sessions": active_sessions,  # í˜„ì¬ í™œì„± ì‚¬ìš©ì ìˆ˜
                "processing_time": f"{end_time - start_time:.1f}s",  # ì²˜ë¦¬ ì†Œìš” ì‹œê°„
                "acceleration": acceleration_type,   # ì‚¬ìš©ëœ ê°€ì† ë°©ì‹
                "model_type": "ë¡œì»¬ ëª¨ë¸" if is_local_model else "ì˜¨ë¼ì¸ ëª¨ë¸"  # ëª¨ë¸ íƒ€ì…
            }
        }

    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒì‹œ ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        import traceback
        print("--- LOAD DOCUMENTS ENDPOINT ERROR ---")
        traceback.print_exc()  # ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
        print("-------------------------------------")
        # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {str(e)}")

@app.post("/api/review")
async def review_statement(request: ReviewRequest):
    """
    ìƒê¸°ë¶€ ë¬¸ì¥ ê²€í†  API ì—”ë“œí¬ì¸íŠ¸
    
    ê¸°ëŠ¥:
    1. ì‚¬ìš©ìê°€ ì‘ì„±í•œ ìƒê¸°ë¶€ ë¬¸ì¥ì„ AIë¡œ ë¶„ì„
    2. ì í•©ì„± í‰ê°€, ê°œì„  ì˜ê²¬, ìˆ˜ì • ì œì•ˆì„ ì œê³µ
    3. ì„¸ì…˜ë³„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
    4. Claude AIë¥¼ í™œìš©í•œ ì „ë¬¸ì ì¸ í”¼ë“œë°± ìƒì„±
    
    Args:
        request (ReviewRequest): ê²€í† í•  ë¬¸ì¥ê³¼ ì„¸ì…˜ ID
        
    Returns:
        ReviewResponse: í‰ê°€, í”¼ë“œë°±, ê°œì„  ì œì•ˆì´ í¬í•¨ëœ ì‘ë‹µ
    """
    # 1ë‹¨ê³„: ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    cleanup_expired_sessions()
    
    # 2ë‹¨ê³„: ì„¸ì…˜ ID ìœ íš¨ì„± ê²€ì‚¬
    if request.session_id not in sessions:
        raise HTTPException(status_code=400, detail="Invalid or expired session ID")
    
    # 3ë‹¨ê³„: ì„¸ì…˜ ë°ì´í„° ë° ë²¡í„°ìŠ¤í† ì–´ íšë“
    session_data = sessions[request.session_id]
    vectorstore = session_data['vectorstore']  # í•´ë‹¹ ì„¸ì…˜ì˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
    
    # 4ë‹¨ê³„: ì…ë ¥ ë¬¸ì¥ ìœ íš¨ì„± ê²€ì‚¬
    if not request.statement:
        raise HTTPException(status_code=400, detail="Statement is required")
    
    try:
        # 5ë‹¨ê³„: Claude AIì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        template = """
ë‹¹ì‹ ì€ ê³ ë“±í•™êµ ìƒê¸°ë¶€ íŠ¹ê¸°ì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ì…ë ¥ëœ ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì„¸ ê°€ì§€ í•­ëª©ì„ í‰ê°€í•´ ì£¼ì„¸ìš”:

â‘  ì í•©ì„± í‰ê°€: í•´ë‹¹ ë¬¸ì¥ì´ ì‘ì„±ìš”ë ¹ì— ì í•©í•œì§€ ê°„ë‹¨íˆ íŒë‹¨í•´ ì£¼ì„¸ìš”.
â‘¡ ê²€í†  ì˜ê²¬: ë¬¸ì¥ì˜ ì¥ì , ë¶€ì¡±í•œ ì , ê°œì„  í¬ì¸íŠ¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
â‘¢ ê°œì„  ì œì•ˆ: ì‘ì„±ìš”ë ¹ì„ ê³ ë ¤í•˜ì—¬ ë¬¸ì¥ì„ ë” ë‚˜ì€ í˜•íƒœì˜ 500ìë¡œ ìˆ˜ì •í•´ ì£¼ì„¸ìš”

ì…ë ¥ ë¬¸ì¥:
{question}

â€» ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ ìˆœì„œì™€ ë²ˆí˜¸(â‘ â‘¡â‘¢)ë¥¼ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
        """

        # 6ë‹¨ê³„: ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶œë ¥
        print("=== REVIEW API DEBUG ===")
        print(f"Session ID: {request.session_id}")
        print(f"Statement: {request.statement}")
        print(f"Vectorstore type: {type(vectorstore)}")
        
        # 7ë‹¨ê³„: AI ì²´ì¸ ìƒì„± (ë²¡í„° ê²€ìƒ‰ + Claude AI ì¡°í•©)
        try:
            chain = create_chain(vectorstore)  # ë²¡í„°ìŠ¤í† ì–´ì™€ Claudeë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±
            print("Chain created successfully")
        except Exception as chain_error:
            print(f"Chain creation error: {str(chain_error)}")
            raise HTTPException(status_code=500, detail=f"Chain creation failed: {str(chain_error)}")
        
        # 8ë‹¨ê³„: Claude API í˜¸ì¶œ ì „ í”„ë¡¬í”„íŠ¸ í™•ì¸ (ë””ë²„ê¹…ìš©)
        print("Claude API í˜¸ì¶œ í”„ë¡¬í”„íŠ¸ ì „ì²´:")
        print(template.replace("{question}", request.statement))
        
        # 9ë‹¨ê³„: AI ì²´ì¸ì„ í†µí•´ ë¬¸ì¥ ë¶„ì„ ì‹¤í–‰
        try:
            response = chain.invoke(request.statement)  # ì‚¬ìš©ì ë¬¸ì¥ì„ AIì—ê²Œ ì „ë‹¬
            print("Chain invoke completed")
        except Exception as invoke_error:
            print(f"Chain invoke error: {str(invoke_error)}")
            raise HTTPException(status_code=500, detail=f"Chain invoke failed: {str(invoke_error)}")
        
        # 10ë‹¨ê³„: Claude ì‘ë‹µì—ì„œ ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        result = getattr(response, "content", None)  # ì‘ë‹µ ê°ì²´ì—ì„œ content ì†ì„± ì¶”ì¶œ
        if not result and isinstance(response, dict):
            result = response.get("content", "")  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° content í‚¤ í™•ì¸
        elif not result:
            result = str(response)  # ë‹¤ë¥¸ í˜•íƒœì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜

        print("Claude API ì‘ë‹µ ì›ë¬¸:\n", result)

        # 11ë‹¨ê³„: Claude ì‘ë‹µì„ ì„¸ ê°€ì§€ í•­ëª©ìœ¼ë¡œ íŒŒì‹±
        eval_part, feedback_part, suggestion_part = "", "", ""
        try:
            # "â‘ ", "â‘¡", "â‘¢" ê¸°í˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¶„í• 
            parts = result.split("â‘ ")[1].split("â‘¡")  # â‘ ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê³  â‘¡ìœ¼ë¡œ ë‹¤ì‹œ ë¶„í• 
            eval_part = parts[0].strip()  # ì í•©ì„± í‰ê°€ ë¶€ë¶„
            feedback_suggestion = parts[1].split("â‘¢")  # â‘¡ì™€ â‘¢ìœ¼ë¡œ ë¶„í• 
            feedback_part = feedback_suggestion[0].strip()  # ê²€í†  ì˜ê²¬ ë¶€ë¶„
            suggestion_part = feedback_suggestion[1].strip()  # ê°œì„  ì œì•ˆ ë¶€ë¶„
        except Exception as parse_error:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì „ì²´ ì‘ë‹µì„ í‰ê°€ ë¶€ë¶„ì— ì €ì¥
            print(f"Parsing error: {str(parse_error)}")
            eval_part = result.strip()

        # 12ë‹¨ê³„: ê° ì„¹ì…˜ì—ì„œ ë¶ˆí•„ìš”í•œ ì œëª© í…ìŠ¤íŠ¸ ì œê±°
        eval_part = remove_heading(eval_part, "ì í•©ì„± í‰ê°€")    # "ì í•©ì„± í‰ê°€:" ë“± ì œëª© ì œê±°
        feedback_part = remove_heading(feedback_part, "ê²€í†  ì˜ê²¬")  # "ê²€í†  ì˜ê²¬:" ë“± ì œëª© ì œê±°
        suggestion_part = remove_heading(suggestion_part, "ê°œì„  ì œì•ˆ")  # "ê°œì„  ì œì•ˆ:" ë“± ì œëª© ì œê±°

        # 13ë‹¨ê³„: ê° ì„¹ì…˜ì˜ ê°€ë…ì„± í–¥ìƒì„ ìœ„í•œ í¬ë§·íŒ…
        eval_part = prettify_evaluation(eval_part)      # í‰ê°€ ì„¹ì…˜ ì´ëª¨ì§€ ë° í¬ë§·íŒ…
        feedback_part = prettify_feedback(feedback_part)  # í”¼ë“œë°± ì„¹ì…˜ ì´ëª¨ì§€ ë° í¬ë§·íŒ…
        suggestion_part = prettify_suggestion(suggestion_part)  # ì œì•ˆ ì„¹ì…˜ í¬ë§·íŒ…

        # 14ë‹¨ê³„: ê°œì„  ì œì•ˆì„ 500ìë¡œ ì œí•œ (ìƒê¸°ë¶€ ê¸€ì ìˆ˜ ì œí•œ)
        suggestion_part = suggestion_part[:500]  # ìµœëŒ€ 500ìê¹Œì§€ë§Œ ì‚¬ìš©
        suggestion_length = len(suggestion_part)  # ì‹¤ì œ ê¸€ì ìˆ˜ ê³„ì‚°

        # 15ë‹¨ê³„: ì„±ê³µ ë¡œê·¸ ì¶œë ¥ ë° ì‘ë‹µ ë°˜í™˜
        print("=== REVIEW API SUCCESS ===")
        return {
            "evaluation": eval_part,          # ì í•©ì„± í‰ê°€ ê²°ê³¼
            "feedback": feedback_part,        # ê²€í†  ì˜ê²¬ ë° í”¼ë“œë°±
            "suggestion": suggestion_part,    # ê°œì„ ëœ ë¬¸ì¥ ì œì•ˆ
            "suggestion_length": suggestion_length  # ì œì•ˆ ë¬¸ì¥ì˜ ê¸€ì ìˆ˜
        }

    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒì‹œ ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ë¡œê·¸ ì¶œë ¥
        import traceback
        print("=== REVIEW API ERROR ===")
        print(f"Error: {str(e)}")
        traceback.print_exc()  # ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
        print("========================")
        # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/sessions")
async def list_sessions():
    """
    í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ API ì—”ë“œí¬ì¸íŠ¸
    
    ê¸°ëŠ¥:
    1. í˜„ì¬ ì„œë²„ì—ì„œ ê´€ë¦¬ ì¤‘ì¸ ëª¨ë“  í™œì„± ì„¸ì…˜ ì •ë³´ ë°˜í™˜
    2. ë§Œë£Œëœ ì„¸ì…˜ë“¤ì„ ë¨¼ì € ì •ë¦¬í•œ í›„ ëª©ë¡ ì œê³µ
    3. ê° ì„¸ì…˜ì˜ ìƒì„± ì‹œê°„, ì˜ì—­, í•™ì—… ìˆ˜ì¤€ ì •ë³´ í¬í•¨
    
    Returns:
        list[SessionInfo]: í™œì„± ì„¸ì…˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    cleanup_expired_sessions()  # ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬ í›„ ëª©ë¡ ë°˜í™˜
    return [
        SessionInfo(
            session_id=session_id,                    # ì„¸ì…˜ ê³ ìœ  ID
            created_at=session_data['created_at'],    # ì„¸ì…˜ ìƒì„± ì‹œê°„
            area=session_data['area'],                # ì„ íƒëœ ì˜ì—­
            academic_level=session_data['academic_level']  # í•™ì—… ìˆ˜ì¤€
        )
        for session_id, session_data in sessions.items()  # ëª¨ë“  í™œì„± ì„¸ì…˜ ìˆœíšŒ
    ]

@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str):
    """
    ì„¸ì…˜ ì‚­ì œ API ì—”ë“œí¬ì¸íŠ¸
    
    ê¸°ëŠ¥:
    1. ì§€ì •ëœ ì„¸ì…˜ IDì˜ ì„¸ì…˜ì„ ê°•ì œë¡œ ì‚­ì œ
    2. ë©”ëª¨ë¦¬ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ ì •ë¦¬
    3. íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ
    
    Args:
        session_id (str): ì‚­ì œí•  ì„¸ì…˜ì˜ ê³ ìœ  ID
        
    Returns:
        dict: ì‚­ì œ ì„±ê³µ ë©”ì‹œì§€
    """
    # 1ë‹¨ê³„: ì„¸ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    try:
        # 2ë‹¨ê³„: ë©”ëª¨ë¦¬ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ ì •ë¦¬
        if 'vectorstore' in sessions[session_id]:
            vectorstore = sessions[session_id]['vectorstore']  # ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ íšë“
            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì •ë¦¬
            if hasattr(vectorstore, '_client') and vectorstore._client:
                try:
                    vectorstore._client.reset()  # í´ë¼ì´ì–¸íŠ¸ ë¦¬ì…‹
                except:
                    pass  # ë¦¬ì…‹ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            del vectorstore  # ê°ì²´ ì‚­ì œë¡œ ë©”ëª¨ë¦¬ í•´ì œ
        
        # 3ë‹¨ê³„: ì„¸ì…˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì œê±°
        del sessions[session_id]  # ë©”ëª¨ë¦¬ì—ì„œ ì„¸ì…˜ ë°ì´í„° ì™„ì „ ì œê±°
        
        # 4ë‹¨ê³„: íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‚­ì œ
        session_dir = os.path.join(CHROMA_DB_DIR, session_id)  # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        if os.path.exists(session_dir):
            import asyncio  # ë¹„ë™ê¸° ì²˜ë¦¬ìš©
            import shutil   # ë””ë ‰í† ë¦¬ ì‚­ì œìš©
            
            async def cleanup_directory():
                """
                ì„¸ì…˜ ë””ë ‰í† ë¦¬ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
                íŒŒì¼ ì ê¸ˆ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¬ì‹œë„ ë¡œì§ í¬í•¨
                """
                max_retries = 3  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
                for attempt in range(max_retries):
                    try:
                        await asyncio.sleep(0.1)  # ì§§ì€ ëŒ€ê¸° (íŒŒì¼ í•¸ë“¤ í•´ì œ ëŒ€ê¸°)
                        shutil.rmtree(session_dir)  # ë””ë ‰í† ë¦¬ ì‚­ì œ
                        break  # ì„±ê³µì‹œ ë£¨í”„ ì¢…ë£Œ
                    except PermissionError:
                        # íŒŒì¼ ê¶Œí•œ ì˜¤ë¥˜ì‹œ ì¬ì‹œë„
                        if attempt < max_retries - 1:
                            await asyncio.sleep(0.5)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                        else:
                            print(f"âš ï¸ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚­ì œ ì§€ì—°ë¨: {session_id}")
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‚­ì œ ì‘ì—… ìˆ˜í–‰ (API ì‘ë‹µ ì§€ì—° ë°©ì§€)
            asyncio.create_task(cleanup_directory())
        
        # 5ë‹¨ê³„: ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {"status": "success", "message": "Session deleted"}
        
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒì‹œ HTTP ì˜¤ë¥˜ë¡œ ë³€í™˜
        raise HTTPException(status_code=500, detail=f"Error deleting session: {str(e)}")

# ================================================================================================
# í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ================================================================================================

def remove_heading(text, heading):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì œëª© ë¶€ë¶„ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        text (str): ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
        heading (str): ì œê±°í•  ì œëª© (ì˜ˆ: "ê°œì„  ì œì•ˆ")
        
    Returns:
        str: ì œëª©ì´ ì œê±°ëœ ê¹”ë”í•œ í…ìŠ¤íŠ¸
    """
    # "ê°œì„  ì œì•ˆ", "ê°œì„  ì œì•ˆ:", "ê°œì„  ì œì•ˆ " ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì œëª© ì œê±°
    for h in [heading, f"{heading}:", f"{heading} "]:
        if text.strip().startswith(h):
            # ì œëª©ê³¼ ì½œë¡ , ê³µë°±, ì¤„ë°”ê¿ˆ, ìŒë”°ì˜´í‘œ ì œê±°
            return text.strip()[len(h):].lstrip(": \n\"")
    return text.strip()  # ì œëª©ì´ ì—†ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜

def prettify_bullet(text, emoji="â€¢"):
    """
    ë§ˆí¬ë‹¤ìš´ ìŠ¤íƒ€ì¼ì˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        text (str): ë³€í™˜í•  í…ìŠ¤íŠ¸
        emoji (str): ì‚¬ìš©í•  ì´ëª¨ì§€ (ê¸°ë³¸ê°’: "â€¢")
        
    Returns:
        str: ì´ëª¨ì§€ë¡œ ë³€í™˜ëœ í…ìŠ¤íŠ¸
    """
    lines = text.split('\n')  # ì¤„ ë‹¨ìœ„ë¡œ ë¶„í• 
    pretty_lines = []
    for line in lines:
        if line.strip().startswith('- '):  # "- "ë¡œ ì‹œì‘í•˜ëŠ” ë¶ˆë¦¿ í¬ì¸íŠ¸ í™•ì¸
            # "- " ì œê±°í•˜ê³  ì´ëª¨ì§€ë¡œ êµì²´
            pretty_lines.append(f"{emoji} {line.strip()[2:]}")
        else:
            pretty_lines.append(line.strip())  # ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
    return '\n'.join(pretty_lines)

def prettify_feedback(text):
    """
    í”¼ë“œë°± í…ìŠ¤íŠ¸ì˜ ê°€ë…ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” í•¨ìˆ˜
    íŠ¹ì • í‚¤ì›Œë“œë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ê³  êµ¬ì¡°í™”
    
    Args:
        text (str): ì›ë³¸ í”¼ë“œë°± í…ìŠ¤íŠ¸
        
    Returns:
        str: ì´ëª¨ì§€ì™€ í¬ë§·íŒ…ì´ ì ìš©ëœ í…ìŠ¤íŠ¸
    """
    # ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
    text = text.replace("ì¥ì :", "\nğŸ’¡ ")        # ì¥ì  â†’ ì „êµ¬ ì´ëª¨ì§€
    text = text.replace("ë¶€ì¡±í•œ ì :", "\nâš ï¸ ")   # ë¶€ì¡±í•œ ì  â†’ ê²½ê³  ì´ëª¨ì§€
    text = text.replace("ê°œì„ í•„ìš”:", "\nğŸ“ ")     # ê°œì„ í•„ìš” â†’ ë©”ëª¨ ì´ëª¨ì§€
    text = text.replace("ê°œì„ ì :", "\nğŸ“ ")       # ê°œì„ ì  â†’ ë©”ëª¨ ì´ëª¨ì§€
    
    # ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ í™”ì‚´í‘œ ì´ëª¨ì§€ë¡œ ë³€í™˜
    text = prettify_bullet(text, emoji="ğŸ‘‰")
    return text.strip()

def prettify_evaluation(text):
    """
    í‰ê°€ í…ìŠ¤íŠ¸ì— ì²´í¬ ì´ëª¨ì§€ë¥¼ ì ìš©í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        text (str): ì›ë³¸ í‰ê°€ í…ìŠ¤íŠ¸
        
    Returns:
        str: ì²´í¬ ì´ëª¨ì§€ê°€ ì ìš©ëœ í…ìŠ¤íŠ¸
    """
    return prettify_bullet(text, emoji="âœ…")  # ì²´í¬ ì´ëª¨ì§€ ì‚¬ìš©

def prettify_suggestion(text):
    """
    ì œì•ˆ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ìŒë”°ì˜´í‘œë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        text (str): ì›ë³¸ ì œì•ˆ í…ìŠ¤íŠ¸
        
    Returns:
        str: ìŒë”°ì˜´í‘œê°€ ì œê±°ëœ ê¹”ë”í•œ í…ìŠ¤íŠ¸
    """
    return text.replace('"', '').strip()  # ìŒë”°ì˜´í‘œ ì œê±° í›„ ê³µë°± ì •ë¦¬

# ================================================================================================
# AI ì²´ì¸ ìƒì„± í•¨ìˆ˜ (ë²¡í„° ê²€ìƒ‰ + Claude AI ì¡°í•©)
# ================================================================================================

def create_chain(vectorstore):
    """
    ë²¡í„° ê²€ìƒ‰ê³¼ Claude AIë¥¼ ê²°í•©í•œ ì²˜ë¦¬ ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    ì²˜ë¦¬ ê³¼ì •:
    1. ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ê¸° ìƒì„±
    2. Claude AI ëª¨ë¸ ì´ˆê¸°í™” (SSL ê²€ì¦ ë¹„í™œì„±í™”)
    3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ ì²´ì¸ êµ¬ì„±
    
    Args:
        vectorstore: ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê°ì²´
        
    Returns:
        chain: LangChain ì²˜ë¦¬ ì²´ì¸ ê°ì²´
    """
    try:
        # 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ê¸° ìƒì„±
        print("Creating retriever...")
        retriever = vectorstore.as_retriever(
            search_type="similarity",        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
            search_kwargs={"k": SEARCH_K}   # ìƒìœ„ 3ê°œ ìœ ì‚¬ ë¬¸ì„œ ë°˜í™˜
        )
        print("Retriever created successfully")
        
        # 2ë‹¨ê³„: Claude AIìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        template = """
        ë‹¹ì‹ ì€ ê³ ë“±í•™êµ ìƒê¸°ë¶€ íŠ¹ê¸°ì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì•„ë˜ ì…ë ¥ëœ ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì„¸ ê°€ì§€ í•­ëª©ì„ í‰ê°€í•´ ì£¼ì„¸ìš”:

        â‘  ì í•©ì„± í‰ê°€: í•´ë‹¹ ë¬¸ì¥ì´ ì‘ì„±ìš”ë ¹ì— ì í•©í•œì§€ ê°„ë‹¨íˆ íŒë‹¨í•´ ì£¼ì„¸ìš”.
        â‘¡ ê²€í†  ì˜ê²¬: ë¬¸ì¥ì˜ ì¥ì , ë¶€ì¡±í•œ ì , ê°œì„  í¬ì¸íŠ¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
        â‘¢ ê°œì„  ì œì•ˆ: ì‘ì„±ìš”ë ¹ì„ ê³ ë ¤í•˜ì—¬ ë¬¸ì¥ì„ ë” ë‚˜ì€ í˜•íƒœì˜ 500ìë¡œ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.

        ì…ë ¥ ë¬¸ì¥:
        {question}

        â€» ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ ìˆœì„œì™€ ë²ˆí˜¸(â‘ â‘¡â‘¢)ë¥¼ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
        """

        # 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°ì²´ ìƒì„±
        print("Creating prompt template...")
        prompt = ChatPromptTemplate.from_template(template)
        print("Prompt template created successfully")
        
        # 4ë‹¨ê³„: Anthropic API í‚¤ í™•ì¸
        api_key = os.getenv("ANTHROPIC_API_KEY")  # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°
        if not api_key:
            raise HTTPException(status_code=500, detail="ANTHROPIC_API_KEY not found")
        
        print("Creating ChatAnthropic model...")
        
        # 5ë‹¨ê³„: SSL ê²€ì¦ ë¹„í™œì„±í™” ì„¤ì • (ê°œë°œ í™˜ê²½ìš©)
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False  # í˜¸ìŠ¤íŠ¸ëª… ê²€ì¦ ë¹„í™œì„±í™”
        ssl_context.verify_mode = ssl.CERT_NONE  # ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™”
        
        # ì „ì—­ SSL ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        ssl._create_default_https_context = lambda: ssl_context
        
        # í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•´ SSL ê²€ì¦ ë¹„í™œì„±í™”
        os.environ['ANTHROPIC_VERIFY_SSL'] = 'false'
        os.environ['REQUESTS_CA_BUNDLE'] = ''
        os.environ['SSL_CERT_FILE'] = ''
        
        # 6ë‹¨ê³„: Claude AI ëª¨ë¸ ê°ì²´ ìƒì„±
        model = ChatAnthropic(
            model_name="claude-3-5-sonnet-20241022",  # ìµœì‹  Claude 3.5 Sonnet ëª¨ë¸
            temperature=0,                            # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ì°½ì˜ì„± ìµœì†Œí™”
            api_key=SecretStr(api_key),              # API í‚¤ (ë³´ì•ˆ ì²˜ë¦¬)
            max_tokens_to_sample=2048,               # ìµœëŒ€ í† í° ìˆ˜ (ê¸´ ì‘ë‹µ í—ˆìš©)
            timeout=60,                              # API íƒ€ì„ì•„ì›ƒ 60ì´ˆ
            stop=None                                # íŠ¹ë³„í•œ ì¤‘ë‹¨ ì¡°ê±´ ì—†ìŒ
        )
        print("ChatAnthropic model created successfully")
        
        # 7ë‹¨ê³„: Anthropic í´ë¼ì´ì–¸íŠ¸ì˜ SSL ê²€ì¦ ë¹„í™œì„±í™”
        if hasattr(model, '_client') and hasattr(model._client, '_client'):
            # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë³µì‚¬
            old_client = model._client._client
            # SSL ê²€ì¦ ë¹„í™œì„±í™”ëœ ìƒˆ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            new_client = httpx.Client(
                verify=False,                         # SSL ê²€ì¦ ë¹„í™œì„±í™”
                timeout=60.0,                        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
                headers=old_client.headers,          # ê¸°ì¡´ í—¤ë” ìœ ì§€
                cookies=old_client.cookies,          # ê¸°ì¡´ ì¿ í‚¤ ìœ ì§€
                auth=old_client.auth,                # ê¸°ì¡´ ì¸ì¦ ìœ ì§€
                follow_redirects=old_client.follow_redirects  # ë¦¬ë‹¤ì´ë ‰íŠ¸ ì„¤ì • ìœ ì§€
            )
            # ë‚´ë¶€ í´ë¼ì´ì–¸íŠ¸ êµì²´
            model._client._client = new_client
            print("Anthropic client SSL verification disabled successfully")
        
        # 8ë‹¨ê³„: LangChain ì²˜ë¦¬ ì²´ì¸ êµ¬ì„±
        print("Creating chain...")
        chain = (
            {"context": retriever, "question": RunnablePassthrough()}  # ê²€ìƒ‰ ê²°ê³¼ì™€ ì§ˆë¬¸ì„ í•¨ê»˜ ì „ë‹¬
            | prompt  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©
            | model   # Claude AI ëª¨ë¸ë¡œ ì²˜ë¦¬
        )
        print("Chain created successfully")
        
        return chain  # ì™„ì„±ëœ ì²´ì¸ ë°˜í™˜
    except Exception as e:
        # ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒì‹œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
        import traceback
        print("=== CREATE CHAIN ERROR ===")
        print(f"Error: {str(e)}")
        traceback.print_exc()
        print("==========================")
        raise HTTPException(status_code=500, detail=f"Chain ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ================================================================================================
# ì„œë²„ ì¢…ë£Œ ì²˜ë¦¬ í•¨ìˆ˜
# ================================================================================================

def cleanup_all_sessions():
    """
    ì„œë²„ ì¢…ë£Œ ì‹œ ëª¨ë“  í™œì„± ì„¸ì…˜ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    ê¸°ëŠ¥:
    1. ëª¨ë“  ì„¸ì…˜ì˜ ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ ì •ë¦¬
    2. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ
    3. ë©”ëª¨ë¦¬ì—ì„œ ì„¸ì…˜ ë°ì´í„° ì™„ì „ ì œê±°
    
    ì£¼ì˜: ì„œë²„ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ í˜¸ì¶œë¨ (atexit ë“±ë¡)
    """
    print("ğŸ§¹ ì„œë²„ ì¢…ë£Œ ì¤‘ - ëª¨ë“  ì„¸ì…˜ ì •ë¦¬...")
    
    # ëª¨ë“  í™œì„± ì„¸ì…˜ì„ ìˆœíšŒí•˜ë©° ì •ë¦¬
    for session_id in list(sessions.keys()):  # ë¦¬ìŠ¤íŠ¸ ë³µì‚¬ë¡œ ì•ˆì „í•œ ìˆœíšŒ
        try:
            if 'vectorstore' in sessions[session_id]:
                vectorstore = sessions[session_id]['vectorstore']  # ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ íšë“
                # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì •ë¦¬
                if hasattr(vectorstore, '_client') and vectorstore._client:
                    vectorstore._client.reset()  # í´ë¼ì´ì–¸íŠ¸ ë¦¬ì…‹
        except:
            pass  # ê°œë³„ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    sessions.clear()  # ì„¸ì…˜ ë”•ì…”ë„ˆë¦¬ ì™„ì „ ì´ˆê¸°í™”

# ================================================================================================
# ì„œë²„ ì‹œì‘ì 
# ================================================================================================

# ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬ í•¨ìˆ˜ ë“±ë¡ (í”„ë¡œê·¸ë¨ ì¢…ë£Œì‹œ ìë™ í˜¸ì¶œ)
atexit.register(cleanup_all_sessions)

# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ ì„œë²„ ì‹œì‘)
if __name__ == "__main__":
    import uvicorn  # ASGI ì„œë²„ (FastAPI ì‹¤í–‰ìš©)
    # uvicornìœ¼ë¡œ FastAPI ì•± ì‹¤í–‰
    uvicorn.run(
        app,               # FastAPI ì•± ê°ì²´
        host="0.0.0.0",    # ëª¨ë“  IPì—ì„œ ì ‘ê·¼ í—ˆìš©
        port=8000          # 8000ë²ˆ í¬íŠ¸ì—ì„œ ì„œë¹„ìŠ¤
    ) 